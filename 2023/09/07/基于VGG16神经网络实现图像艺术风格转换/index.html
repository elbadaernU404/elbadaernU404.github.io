<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>基于vgg16神经网络实现图像艺术风格转换 | 青域</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="VGG卷积神经网络">
  
  
  
  
  <meta name="description" content="基本原理通过vgg16或其他神经网络提取图像特征，并使用格拉姆矩阵（Gram matrix）进行图像风格的迁移。 VGG16不必多说，2014年ImageNet图像分类竞赛亚军，定位竞赛冠军；VGG网络采用连续的小卷积核（3x3）和池化层构建深度神经网络，网络深度可以达到16层或19层，其中VGG16和VGG19最为著名。VGG16和VGG19网络架构非常相似，都由多个卷积层和池化层交替堆叠而成">
<meta name="keywords" content="VGG,卷积神经网络">
<meta property="og:type" content="article">
<meta property="og:title" content="基于VGG16神经网络实现图像艺术风格转换">
<meta property="og:url" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/index.html">
<meta property="og:site_name" content="青域">
<meta property="og:description" content="基本原理通过vgg16或其他神经网络提取图像特征，并使用格拉姆矩阵（Gram matrix）进行图像风格的迁移。 VGG16不必多说，2014年ImageNet图像分类竞赛亚军，定位竞赛冠军；VGG网络采用连续的小卷积核（3x3）和池化层构建深度神经网络，网络深度可以达到16层或19层，其中VGG16和VGG19最为著名。VGG16和VGG19网络架构非常相似，都由多个卷积层和池化层交替堆叠而成">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/A.png">
<meta property="og:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/B.png">
<meta property="og:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/C.png">
<meta property="og:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/D.png">
<meta property="og:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/1000.jpg">
<meta property="og:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/12000.jpg">
<meta property="og:updated_time" content="2024-04-18T10:07:42.612Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="基于VGG16神经网络实现图像艺术风格转换">
<meta name="twitter:description" content="基本原理通过vgg16或其他神经网络提取图像特征，并使用格拉姆矩阵（Gram matrix）进行图像风格的迁移。 VGG16不必多说，2014年ImageNet图像分类竞赛亚军，定位竞赛冠军；VGG网络采用连续的小卷积核（3x3）和池化层构建深度神经网络，网络深度可以达到16层或19层，其中VGG16和VGG19最为著名。VGG16和VGG19网络架构非常相似，都由多个卷积层和池化层交替堆叠而成">
<meta name="twitter:image" content="http://yoursite.com/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/A.png">
  
    <link rel="alternate" href="/atom.xml" title="青域" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/dialog.css">
  

  

  
    <link rel="stylesheet" href="/css/header-post.css">
  

  
  
  

</head>
</html>

  <body data-spy="scroll" data-target="#toc" data-offset="50">


  
  <div id="container">
    <div id="wrap">
      
        <header>

    <div id="allheader" class="navbar navbar-default navbar-static-top" role="navigation">
        <div class="navbar-inner">
          
          <div class="container"> 
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>

            
              <a class="brand" style="
                 margin-top: 0px;"  
                href="#" data-toggle="modal" data-target="#myModal" >
                  <img width="124px" height="124px" alt="Hike News" src="/css/images/mylogo.jpg">
              </a>
            
            
            <div class="navbar-collapse collapse">
              <ul class="hnav navbar-nav">
                
                  <li> <a class="main-nav-link" href="/">Home</a> </li>
                
                  <li> <a class="main-nav-link" href="/archives">Archives</a> </li>
                
                  <li> <a class="main-nav-link" href="/categories">Categories</a> </li>
                
                  <li> <a class="main-nav-link" href="/tags">Tags</a> </li>
                
                  <li> <a class="main-nav-link" href="/about">About</a> </li>
                
                  <li><div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div></li>
            </div>
          </div>
                
      </div>
    </div>

</header>



      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-基于VGG16神经网络实现图像艺术风格转换" style="width: 75%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      基于VGG16神经网络实现图像艺术风格转换
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/" class="article-date">
	  <time datetime="2023-09-07T07:04:43.000Z" itemprop="datePublished">2023-09-07</time>
	</a>

      
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>

      
	<a class="article-views">
	<span id="busuanzi_container_page_pv">
		PV:<span id="busuanzi_value_page_pv"></span>
	</span>
	</a>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script src="\assets\js\APlayer.min.js"> </script><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>通过vgg16或其他神经网络提取图像特征，并使用格拉姆矩阵（Gram matrix）进行图像风格的迁移。</p>
<h3 id="VGG16"><a href="#VGG16" class="headerlink" title="VGG16"></a>VGG16</h3><p>不必多说，2014年ImageNet图像分类竞赛亚军，定位竞赛冠军；VGG网络采用连续的小卷积核（3x3）和池化层构建深度神经网络，网络深度可以达到16层或19层，其中VGG16和VGG19最为著名。VGG16和VGG19网络架构非常相似，都由多个卷积层和池化层交替堆叠而成，最后使用全连接层进行分类。两者的区别在于网络的深度和参数量，VGG19相对于VGG16增加了3个卷积层和一个全连接层，参数量也更多。</p>
<p>可在keras直接使用vgg16/19源码，自动下载相关预训练模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br></pre></td></tr></table></figure>
<p>这里结合transform，在torch中构建神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># VGG16神经网络定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG16</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""Vgg16 Net"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, requires_grad=False)</span>:</span></span><br><span class="line">        super(VGG16, self).__init__()</span><br><span class="line">        vgg_pretrained_features = models.vgg16(pretrained=<span class="literal">True</span>).features</span><br><span class="line">        self.slice1 = torch.nn.Sequential()</span><br><span class="line">        self.slice2 = torch.nn.Sequential()</span><br><span class="line">        self.slice3 = torch.nn.Sequential()</span><br><span class="line">        self.slice4 = torch.nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            self.slice1.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">4</span>, <span class="number">9</span>):</span><br><span class="line">            self.slice2.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">9</span>, <span class="number">16</span>):</span><br><span class="line">            self.slice3.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">16</span>, <span class="number">23</span>):</span><br><span class="line">            self.slice4.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> requires_grad:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> self.parameters():</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        h = self.slice1(X)</span><br><span class="line">        h_relu1_2 = h</span><br><span class="line">        h = self.slice2(h)</span><br><span class="line">        h_relu2_2 = h</span><br><span class="line">        h = self.slice3(h)</span><br><span class="line">        h_relu3_3 = h</span><br><span class="line">        h = self.slice4(h)</span><br><span class="line">        h_relu4_3 = h</span><br><span class="line"></span><br><span class="line">        vgg_outputs = namedtuple(<span class="string">"VggOutputs"</span>, [<span class="string">"relu1_2"</span>, <span class="string">"relu2_2"</span>, <span class="string">"relu3_3"</span>, <span class="string">"relu4_3"</span>])</span><br><span class="line">        output = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransformerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(TransformerNet, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            ConvBlock(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">9</span>, stride=<span class="number">1</span>),</span><br><span class="line">            ConvBlock(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            ConvBlock(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ConvBlock(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, upsample=<span class="literal">True</span>),</span><br><span class="line">            ConvBlock(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, upsample=<span class="literal">True</span>),</span><br><span class="line">            ConvBlock(<span class="number">32</span>, <span class="number">3</span>, kernel_size=<span class="number">9</span>, stride=<span class="number">1</span>, normalize=<span class="literal">False</span>, relu=<span class="literal">False</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, channels)</span>:</span></span><br><span class="line">        super(ResidualBlock, self).__init__()</span><br><span class="line">        self.block = nn.Sequential(</span><br><span class="line">            ConvBlock(channels, channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, normalize=<span class="literal">True</span>, relu=<span class="literal">True</span>),</span><br><span class="line">            ConvBlock(channels, channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, normalize=<span class="literal">True</span>, relu=<span class="literal">False</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.block(x) + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvBlock</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, upsample=False, normalize=True, relu=True)</span>:</span></span><br><span class="line">        super(ConvBlock, self).__init__()</span><br><span class="line">        self.upsample = upsample</span><br><span class="line">        self.block = nn.Sequential(</span><br><span class="line">            nn.ReflectionPad2d(kernel_size // <span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size, (stride,))</span><br><span class="line">        )</span><br><span class="line">        self.norm = nn.InstanceNorm2d(out_channels, affine=<span class="literal">True</span>) <span class="keyword">if</span> normalize <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.relu = relu</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.upsample:</span><br><span class="line">            x = F.interpolate(x, scale_factor=<span class="number">2</span>)</span><br><span class="line">        x = self.block(x)</span><br><span class="line">        <span class="keyword">if</span> self.norm <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.norm(x)</span><br><span class="line">        <span class="keyword">if</span> self.relu:</span><br><span class="line">            x = F.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">测试模型</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    input1 = torch.rand([<span class="number">224</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>])</span><br><span class="line">    model_x = VGG16()</span><br><span class="line">    print(model_x)</span><br></pre></td></tr></table></figure>
<h3 id="格拉姆矩阵"><a href="#格拉姆矩阵" class="headerlink" title="格拉姆矩阵"></a>格拉姆矩阵</h3><p>格拉姆矩阵（Gram matrix）即n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，是一个对称矩阵。</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/A.png" alt></p>
<p>更直观的理解：</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/B.png" alt></p>
<p>输入图像的feature map为[ ch, h, w]。我们经过flatten（即是将h<em>w进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h</em>w]和[ h*w, ch]的矩阵。再对两个作内积得到格拉姆矩阵。</p>
<p>使用格拉姆矩阵进行风格迁移：</p>
<p>1.准备目标图像和目标风格图像；</p>
<p>2.使用深层网络加白噪声提取目标图像和风格目标的特征向量。对两个图像的特征向量计算格拉姆矩阵，以矩阵差异最小化为优化目标，不断调整目标图像，使风格不断相似。</p>
<p>torch中格拉姆矩阵代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(y)</span>:</span></span><br><span class="line">    (b, c, h, w) = y.size()</span><br><span class="line">    features = y.view(b, c, w * h)</span><br><span class="line">    features_t = features.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    gram = features.bmm(features_t) / (c * h * w)</span><br><span class="line">    <span class="keyword">return</span> gram</span><br></pre></td></tr></table></figure>
<h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><p>准备训练文件和风格图片，例如随机图像*20和梵高名作星月夜</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/C.png" alt></p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/D.png" alt></p>
<h3 id="utils-py工具"><a href="#utils-py工具" class="headerlink" title="utils.py工具"></a>utils.py工具</h3><p>配置训练参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"Parser 4 Training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--style"</span>, type=str, default=<span class="string">"images/styles/the_starry_night.jpg"</span>, help=<span class="string">"Path 2 style image"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--dataset"</span>, type=str, help=<span class="string">"path 2 training dataset"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--epochs"</span>, type=int, default=<span class="number">1</span>, help=<span class="string">"Number of training epochs"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--batch_size"</span>, type=int, default=<span class="number">4</span>, help=<span class="string">"Batch size 4 training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--image_size"</span>, type=int, default=<span class="number">256</span>, help=<span class="string">"Size of training images"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--style_size"</span>, type=int, help=<span class="string">"Size of style image"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lr"</span>, type=float, default=<span class="number">1e-3</span>, help=<span class="string">"Learning rate"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lambda_img"</span>, type=float, default=<span class="number">1e5</span>, help=<span class="string">"Weight 4 image loss"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lambda_style"</span>, type=float, default=<span class="number">1e10</span>, help=<span class="string">"Weight 4 style loss"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--model_path"</span>, type=str, help=<span class="string">"Optional path 2 checkpoint model"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--model_checkpoint"</span>, type=int, default=<span class="number">1000</span>, help=<span class="string">"Batches 4 saving model"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--result_checkpoint"</span>, type=int, default=<span class="number">1000</span>, help=<span class="string">"Batches 4 saving image result"</span>)</span><br></pre></td></tr></table></figure>
<p>使用神经网络进行风格训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_transform</span><span class="params">(image_size)</span>:</span></span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [</span><br><span class="line">            transforms.Resize(int(image_size * <span class="number">1.15</span>)),</span><br><span class="line">            transforms.RandomCrop(image_size),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize(mean, std),</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> transform</span><br></pre></td></tr></table></figure>
<p>使用神经网络进行风格转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_transform</span><span class="params">(image_size=None)</span>:</span></span><br><span class="line">    resize = [transforms.Resize(image_size)] <span class="keyword">if</span> image_size <span class="keyword">else</span> []</span><br><span class="line">    transform = transforms.Compose(resize + [transforms.ToTensor(), transforms.Normalize(mean, std)])</span><br><span class="line">    <span class="keyword">return</span> transform</span><br></pre></td></tr></table></figure>
<p>使用均值和标准对图像张量进行反规范化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">denormalize</span><span class="params">(tensors)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        tensors[:, c].mul_(std[c]).add_(mean[c])</span><br><span class="line">    <span class="keyword">return</span> tensors</span><br></pre></td></tr></table></figure>
<h3 id="train-py训练脚本"><a href="#train-py训练脚本" class="headerlink" title="train.py训练脚本"></a>train.py训练脚本</h3><p>训练配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_args = TrainArgs()</span><br><span class="line">args = train_args.initialize().parse_args()</span><br><span class="line"></span><br><span class="line">args.dataset = <span class="string">'./dataset'</span></span><br><span class="line">args.style = <span class="string">'./images/styles/the_starry_night.jpg'</span></span><br><span class="line">args.epochs = <span class="number">2400</span> <span class="comment"># epochs*(数据集/batch_size)是1000的公倍数</span></span><br><span class="line">args.batch_size = <span class="number">4</span></span><br><span class="line">args.image_size = <span class="number">256</span></span><br></pre></td></tr></table></figure>
<p>训练流程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">style_name = args.style.split(<span class="string">"/"</span>)[<span class="number">-1</span>].split(<span class="string">"."</span>)[<span class="number">0</span>]</span><br><span class="line">os.makedirs(<span class="string">f"images/train/<span class="subst">&#123;style_name&#125;</span>_training"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">os.makedirs(<span class="string">f"checkpoints"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">train_dataset = datasets.ImageFolder(args.dataset, train_transform(args.image_size))</span><br><span class="line">dataloader = DataLoader(train_dataset, batch_size=args.batch_size)</span><br><span class="line">transformer = TransformerNet().to(device)</span><br><span class="line">vgg = VGG16(requires_grad=<span class="literal">False</span>).to(device)</span><br><span class="line"><span class="keyword">if</span> args.model_path:</span><br><span class="line">    transformer.load_state_dict(torch.load(args.model_path))</span><br><span class="line">optimizer = Adam(transformer.parameters(), args.lr)</span><br><span class="line">l2_loss = torch.nn.MSELoss().to(device)</span><br><span class="line">style = style_transform(args.style_size)(Image.open(args.style))</span><br><span class="line">style = style.repeat(args.batch_size, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line">features_style = vgg(style)</span><br><span class="line">gram_style = [gram_matrix(y) <span class="keyword">for</span> y <span class="keyword">in</span> features_style]</span><br><span class="line">image_samples = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> random.sample(glob.glob(<span class="string">f"<span class="subst">&#123;args.dataset&#125;</span>/*/*"</span>), len(train_dataset)):</span><br><span class="line">    image_samples += [style_transform(args.image_size)(Image.open(path).resize((<span class="number">224</span>, <span class="number">224</span>)))]</span><br><span class="line">image_samples = torch.stack(image_samples)</span><br></pre></td></tr></table></figure>
<p>启动训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_result</span><span class="params">(sample)</span>:</span></span><br><span class="line">    transformer.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = transformer(image_samples.to(device))</span><br><span class="line">    image_rgb = denormalize(torch.cat((image_samples.cpu(), output.cpu()), <span class="number">2</span>))</span><br><span class="line">    save_image(image_rgb, <span class="string">f"images/train/<span class="subst">&#123;style_name&#125;</span>_training/<span class="subst">&#123;sample&#125;</span>.jpg"</span>, nrow=<span class="number">4</span>)</span><br><span class="line">    transformer.train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_model</span><span class="params">(sample)</span>:</span></span><br><span class="line">    torch.save(transformer.state_dict(), <span class="string">f"checkpoints/<span class="subst">&#123;style_name&#125;</span>_<span class="subst">&#123;sample&#125;</span>.pth"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(args.epochs):</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> range(len(dataloader)):</span><br><span class="line">        batch_i = line</span><br><span class="line">        batches_done = epoch * len(dataloader) + batch_i + <span class="number">1</span></span><br><span class="line">        images = list(dataloader)[line][<span class="number">0</span>]</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        images_original = images.to(device)</span><br><span class="line">        images_transformed = transformer(images_original)</span><br><span class="line"></span><br><span class="line">        features_original = vgg(images_original)</span><br><span class="line">        features_transformed = vgg(images_transformed)</span><br><span class="line"></span><br><span class="line">        img_loss = args.lambda_img * l2_loss(features_transformed.relu2_2, features_original.relu2_2)</span><br><span class="line"></span><br><span class="line">        style_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> ft_y, gm_s <span class="keyword">in</span> zip(features_transformed, gram_style):</span><br><span class="line">            gm_y = gram_matrix(ft_y)</span><br><span class="line">            style_loss += l2_loss(gm_y, gm_s[: images.size(<span class="number">0</span>), :, :])</span><br><span class="line">        style_loss *= args.lambda_style</span><br><span class="line"></span><br><span class="line">        total_loss = img_loss + style_loss</span><br><span class="line">        total_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batches_done % args.result_checkpoint == <span class="number">0</span>:</span><br><span class="line">            save_result(batches_done)</span><br><span class="line">        <span class="keyword">if</span> args.model_checkpoint &gt; <span class="number">0</span> <span class="keyword">and</span> batches_done % args.model_checkpoint == <span class="number">0</span>:</span><br><span class="line">            save_model(batches_done)</span><br></pre></td></tr></table></figure>
<p>第1000次迭代</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/1000.jpg" alt></p>
<p>第12000次迭代（2400epoch * (20/batch_size)），效果明显</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/12000.jpg" alt></p>
<p>到这一步，训练结束，可以预测结果</p>
<h2 id="预测："><a href="#预测：" class="headerlink" title="预测："></a>预测：</h2><p>配置预测参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predict_args = PredictArgs()</span><br><span class="line">args = predict_args.initialize().parse_args()</span><br><span class="line">args.image_path = <span class="string">'./images/input/001.jpg'</span></span><br><span class="line">args.model_path = <span class="string">'./checkpoints/the_starry_night_12000.pth'</span></span><br></pre></td></tr></table></figure>
<p>预测代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">os.makedirs(<span class="string">"images/output"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">   device = torch.device(<span class="string">'cpu'</span>)<span class="comment">#("cuda" if torch.cuda.is_available() else "cpu")</span></span><br><span class="line">   transform = style_transform()</span><br><span class="line">   transformer = TransformerNet().to(device)</span><br><span class="line">   transformer.load_state_dict(torch.load(mod_path))</span><br><span class="line">   transformer.eval()</span><br><span class="line">   image_tensor = Variable(transform(Image.open(img_path))).to(device)</span><br><span class="line">   image_tensor = image_tensor.unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">       output_image = denormalize(transformer(image_tensor)).cpu()</span><br><span class="line">       </span><br><span class="line">   name = img_path.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">   save_image(output_image, <span class="string">f"images/output/output_<span class="subst">&#123;name&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="思路·参考"><a href="#思路·参考" class="headerlink" title="思路·参考"></a>思路·参考</h2><p><a href="https://github.com/elleryqueenhomels/fast_neural_style_transfer/tree/master" target="_blank" rel="noopener">https://github.com/elleryqueenhomels/fast_neural_style_transfer/tree/master</a></p>
<p><a href="https://github.com/AaronJny/DeepLearningExamples/tree/master/tf2-neural-style-transfer" target="_blank" rel="noopener">https://github.com/AaronJny/DeepLearningExamples/tree/master/tf2-neural-style-transfer</a></p>
<p><a href="https://github.com/Huage001/PaintTransformer" target="_blank" rel="noopener">https://github.com/Huage001/PaintTransformer</a></p>
<p><a href="https://github.com/eriklindernoren/Fast-Neural-Style-Transfer/tree/master" target="_blank" rel="noopener">https://github.com/eriklindernoren/Fast-Neural-Style-Transfer/tree/master</a></p>
<p><a href="https://github.com/NeverGiveU/PaintTransformer-Pytorch-master" target="_blank" rel="noopener">https://github.com/NeverGiveU/PaintTransformer-Pytorch-master</a></p>
<p><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" target="_blank" rel="noopener">https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</a></p>

      
    </div>
    <footer class="article-footer">
      
      
        
	<div id="comment">
		<!-- 来必力City版安装代码 -->
		<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTQ4MS82MDQ5">
		<script type="text/javascript">
		   (function(d, s) {
		       var j, e = d.getElementsByTagName(s)[0];

		       if (typeof LivereTower === 'function') { return; }

		       j = d.createElement(s);
		       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
		       j.async = true;

		       e.parentNode.insertBefore(j, e);
		   })(document, 'script');
		</script>
		<noscript>为正常使用来必力评论功能请激活JavaScript</noscript>
		</div>
		<!-- City版安装代码已完成 -->
	</div>



      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VGG/">VGG</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/卷积神经网络/">卷积神经网络</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2023/09/27/Nebula3单机版快速安装/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Nebula3单机版快速安装
        
      </div>
    </a>
  
  
    <a href="/2023/08/31/paddleDetection Demo/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">paddleDetection Demo</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="toc-sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">Contents</strong>
    
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本原理"><span class="nav-number">1.</span> <span class="nav-text">基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#VGG16"><span class="nav-number">1.1.</span> <span class="nav-text">VGG16</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#格拉姆矩阵"><span class="nav-number">1.2.</span> <span class="nav-text">格拉姆矩阵</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#开始训练"><span class="nav-number">2.</span> <span class="nav-text">开始训练</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#utils-py工具"><span class="nav-number">2.1.</span> <span class="nav-text">utils.py工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#train-py训练脚本"><span class="nav-number">2.2.</span> <span class="nav-text">train.py训练脚本</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预测："><span class="nav-number">3.</span> <span class="nav-text">预测：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#思路·参考"><span class="nav-number">4.</span> <span class="nav-text">思路·参考</span></a></li></ol>
    
    </div>
  </aside>
</section>
        
      </div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2025 青域 All Rights Reserved.</p>

	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>




  <script src="/js/dialog.js"></script>








	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            青域
          </div>
          <div class="panel-body">
            Copyright © 2025 tianL.R All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
    <a id="menu-switch"><i class="fa fa-bars fa-lg"></i></a>
  
</script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"left","width":170,"height":340},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>