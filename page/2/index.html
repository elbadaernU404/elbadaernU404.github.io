<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>青域</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  
  
  
  <meta name="description" content="personal IT related station">
<meta property="og:type" content="website">
<meta property="og:title" content="青域">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="青域">
<meta property="og:description" content="personal IT related station">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="青域">
<meta name="twitter:description" content="personal IT related station">
  
    <link rel="alternate" href="/atom.xml" title="青域" type="application/atom+xml">
  

  

  <link rel="icon" href="/css/images/mylogo.jpg">
  <link rel="apple-touch-icon" href="/css/images/mylogo.jpg">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>
  <script src="/js/bootstrap.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">

  
    <link rel="stylesheet" href="/css/home.css">
  

  

  

  
  
  

</head>
</html>

  <body>


  
    <header id="header">

	<!-- 背景图模式 -->
	

    
      <div id="intrologo" class="intro-logo" style="background-position:center; background-repeat:no-repeat; background-image: url(); background-size: auto 100%;">

      <!-- Support rolling -->  
        
        <section class="awSlider">
          <div class="carousel slide carousel-fade " data-ride="carousel">

            <!-- Wrapper for slides -->
            <div class="carousel-inner">
               
                  
                    <div class="item active">
                  
                    <img id="carousel-img0" src="/css/images/home-bg.jpg">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img0 = new Image();
                      var imageTag0 = document.getElementById("carousel-img0");
                      img0.src = imageTag0.src;
                      img0.onload=function(){
                        if (img0.width / img0.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag0.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag0.style.height = document.body.clientHeight + "px";
                          imageTag0.style.marginLeft = -(document.body.clientHeight * img0.width / img0.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img1" src="/css/images/sample.jpg">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img1 = new Image();
                      var imageTag1 = document.getElementById("carousel-img1");
                      img1.src = imageTag1.src;
                      img1.onload=function(){
                        if (img1.width / img1.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag1.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag1.style.height = document.body.clientHeight + "px";
                          imageTag1.style.marginLeft = -(document.body.clientHeight * img1.width / img1.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
                  
                    <div class="item">
                  
                    <img id="carousel-img2" src="https://api.isoyu.com/bing_images.php">
                  </div>

                  <!-- 自适应大图 -->
                  <script>
                      var img2 = new Image();
                      var imageTag2 = document.getElementById("carousel-img2");
                      img2.src = imageTag2.src;
                      img2.onload=function(){
                        if (img2.width / img2.height <= document.body.clientWidth / document.body.clientHeight) {
                          imageTag2.style.width = document.body.clientWidth + "px";
                        } else {
                          imageTag2.style.height = document.body.clientHeight + "px";
                          imageTag2.style.marginLeft = -(document.body.clientHeight * img2.width / img2.height - document.body.clientWidth) / 2 + "px";
                        }
                      };
                  </script>
                
            </div>

            <!-- Controls -->
            <a class="left carousel-control" href=".carousel" role="button" data-slide="prev">
              <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
              <span class="sr-only">Geri</span>
            </a>
            <a class="right carousel-control" href=".carousel" role="button" data-slide="next">
              <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
              <span class="sr-only">İleri</span>
            </a>
          </div>
        </section>
        <script>
          $('section.awSlider .carousel').carousel({
              pause: '',
              interval: 5000
          });
          var startImage = $('section.awSlider .item.active > img').attr('src');
          $('section.awSlider .carousel').on('slid.bs.carousel', function () {
              var bscn = $(this).find('.item.active > img').attr('src');
              $('section.awSlider > img').attr('src', bscn);
          });
        </script>
      

    
 


    <canvas width="100%" height="100%"></canvas>
    <script>
      var c = document.getElementsByTagName('canvas')[0],
          x = c.getContext('2d'),
          w = window.innerWidth,
          h = window.innerHeight,
          pr = window.devicePixelRatio || 1,
          f = 90,
          q,
          m = Math,
          r = 0,
          u = m.PI*2,
          v = m.cos,
          z = m.random
      c.width = w*pr
      c.height = h*pr
      x.scale(pr, pr)
      x.globalAlpha = 0.6

      <!-- 折线Polyline背景 -->
      
    </script>
    

    
      <div id="homelogo" class="homelogo" style="background: rgba(255,255,255,1);"> 
    

        
          <div class="homelogoback"  style="border: 1px solid #404040;" >
            <h1><a href="#content" id="logo">青域</a></h1>
            <h3>personal IT related station</h3>
            <h5>tianL.R</h5>
            <!-- <p><a href="https://github.com/iTimeTraveler" target="_blank">Github</a></p> -->
          </div>
        
    
    </div>
  </div>

  <!-- 自适应主页背景大图 -->
  

 <!-- home_logo_image居中 -->
 
    <script>
        var homelogodiv = document.getElementById("homelogo");
        if (document.all.homelogo.offsetWidth > document.body.clientWidth) {
          homelogodiv.style.width = document.body.clientWidth + "px";
          homelogodiv.style.marginLeft = document.body.clientWidth * -0.5 + "px";
        } else {
          homelogodiv.style.width = homelogodiv.clientWidth  + "px";
          homelogodiv.style.marginLeft = (homelogodiv.clientWidth)  * -0.5 + "px";
        }
    </script>
  

  <div class="intro-navigate">
      <p class="navigater-list">
        
          <a id="beautifont" class="main-nav-link" href="/">Home</a>
        
          <a id="beautifont" class="main-nav-link" href="/archives">Archives</a>
        
          <a id="beautifont" class="main-nav-link" href="/categories">Categories</a>
        
          <a id="beautifont" class="main-nav-link" href="/tags">Tags</a>
        
          <a id="beautifont" class="main-nav-link" href="/about">About</a>
        
      </p>
  </div>

</header>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=461347998&auto=0&height=66"></iframe>
  
  <div id="container">
    <div id="wrap">
      
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;">
  
    <article id="post-基于VGG神经网络实现以图搜图"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2024/01/02/基于VGG神经网络实现以图搜图/">基于VGG16神经网络实现以图搜图</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2024/01/02/基于VGG神经网络实现以图搜图/" class="article-date">
	  <time datetime="2024-01-02T11:11:22.000Z" itemprop="datePublished">2024-01-02</time>
	</a>

      
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p><font color="gold"> <strong>·</strong> </font>预先准备一份图片库，并对其中数据进行批处理操作，使用VGG16卷积神经网络提取图像的512维卷积特征，刷入数据库（ClickHouse）记录；</p>
<p><font color="gold"> <strong>·</strong> </font>上传目标图像进行识图，同样使用VGG16提取目标图像特征，使用CK数据库距离函数进行匹配，高于阈值即可返回识图结果</p>
<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author : tianL.R</span></span><br><span class="line"><span class="comment"># @Email : rtl1312@163.com</span></span><br><span class="line"><span class="comment"># @Time : 2023.11.26</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG16Net</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.input_shape = (<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)</span><br><span class="line">        self.weight = <span class="string">'imagenet'</span></span><br><span class="line">        self.pooling = <span class="string">'max'</span></span><br><span class="line">        self.model_vgg = VGG16(weights=self.weight,</span><br><span class="line">                               input_shape=(self.input_shape[<span class="number">0</span>], self.input_shape[<span class="number">1</span>], self.input_shape[<span class="number">2</span>],),</span><br><span class="line">                               pooling=self.pooling,</span><br><span class="line">                               include_top=<span class="literal">False</span>)</span><br><span class="line">        self.model_vgg.predict(np.zeros((<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>)))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detection</span><span class="params">(self, img_path)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        提取VGG16最后一层卷积特征</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># img = image.load_img(img_path, target_size=(self.input_shape[0], self.input_shape[1]))</span></span><br><span class="line">        img = img_path.resize((self.input_shape[<span class="number">0</span>], self.input_shape[<span class="number">1</span>]))</span><br><span class="line">        img = image.img_to_array(img)</span><br><span class="line">        img = np.expand_dims(img, axis=<span class="number">0</span>)</span><br><span class="line">        img = preprocess_input(img)</span><br><span class="line">        feat = self.model_vgg.predict(img)</span><br><span class="line">        norm_feat = feat[<span class="number">0</span>] / linalg.norm(feat[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> norm_feat.tolist()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    img1 = <span class="string">'333.jpg'</span></span><br><span class="line">    img2 = <span class="string">'555.jpg'</span></span><br><span class="line">    img1 = Image.open(img1)</span><br><span class="line">    img2 = Image.open(img2)</span><br><span class="line"></span><br><span class="line">    vgg = VGG16Net()</span><br><span class="line">    queryVec1 = np.array(vgg.detection(img1))</span><br><span class="line">    queryVec2 = np.array(vgg.detection(img2))</span><br><span class="line">    scores = np.dot(queryVec1, queryVec2)</span><br><span class="line">    score2 = queryVec1.dot(queryVec2) / (np.linalg.norm(queryVec1) * np.linalg.norm(queryVec2))</span><br><span class="line">    print(scores)</span><br><span class="line">    print(score2)</span><br></pre></td></tr></table></figure>
        <!--  思路 · 预先准备一份图片库，并对其中数据进行批处理操作，使用VGG16卷积神经网络提取图像的512维卷积特征，刷入数据库（ClickHouse）记录；
 · 上传目标图像进行识图，同样使用VGG16提取目标图像特征，使用CK数据库距离函数进行匹配，高于阈值即可返回识图结果
神经网络123456789101112131415161718192021222324252627282930313......  -->
        <p class="article-more-link">
          <a href="/2024/01/02/基于VGG神经网络实现以图搜图/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VGG/">VGG</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/卷积神经网络/">卷积神经网络</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-卷积神经网络图像分类算法小集"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2024/01/01/卷积神经网络图像分类算法小集/">卷积神经网络图像分类算法小集</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2024/01/01/卷积神经网络图像分类算法小集/" class="article-date">
	  <time datetime="2024-01-01T02:12:35.000Z" itemprop="datePublished">2024-01-01</time>
	</a>

      
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><h3 id="训练结构"><a href="#训练结构" class="headerlink" title="训练结构"></a>训练结构</h3><p><font color="gold"><strong>·</strong></font> 在项目根目录下新建数据集文件夹<code>data_set</code>，建立子文件夹（数据集名称）用于存放训练集和测试集；</p>
<p><font color="gold"><strong>·</strong></font> 在项目根目录下新建数据集文件夹<code>class_j</code>，用于存放分类json文件；</p>
<p><font color="gold"><strong>·</strong></font> 在项目根目录下新建数据集文件夹<code>models</code>，用于存放训练好的模型文件；</p>
<p><font color="gold"><strong>·</strong></font> 神经网络<code>model.py</code>；</p>
<p><font color="gold"><strong>·</strong></font> 训练脚本<code>train.py</code>；</p>
<p><font color="gold"><strong>·</strong></font> 预测脚本<code>predict.py</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> project</span></span><br><span class="line">├── data_set</span><br><span class="line">│	├── data</span><br><span class="line">│	     ├── train</span><br><span class="line">│	     │    ├── 00001.jpg</span><br><span class="line">│	     │    ├── 00002.jpg</span><br><span class="line">│	     │    ├── 00003.jpg</span><br><span class="line">│	     │    ├── ...</span><br><span class="line">│	     │    └── 10000.jpg</span><br><span class="line">│	     └── val</span><br><span class="line">│	          ├── 00001.jpg</span><br><span class="line">│	          ├── 00002.jpg</span><br><span class="line">│	          ├── 00003.jpg</span><br><span class="line">│	          ├── ...</span><br><span class="line">│	          └── 01000.jpg</span><br><span class="line">├── class_j</span><br><span class="line">│	├── class_indices.json</span><br><span class="line">├── models</span><br><span class="line">│	├── model.pth</span><br><span class="line">├── model.py</span><br><span class="line">├── train.py</span><br><span class="line">└── predict.py</span><br></pre></td></tr></table></figure>
<h3 id="封装结构"><a href="#封装结构" class="headerlink" title="封装结构"></a>封装结构</h3><p>以<code>GoogLeNet</code>神经网络为例：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> GoogLeNet</span></span><br><span class="line">├── class_j</span><br><span class="line">│	├── class_indices.json</span><br><span class="line">│── weights</span><br><span class="line">│	├── GoogLeNet_GPU_v1.pth</span><br><span class="line">└── model.py</span><br></pre></td></tr></table></figure>
        <!--  目录结构训练结构· 在项目根目录下新建数据集文件夹data_set，建立子文件夹（数据集名称）用于存放训练集和测试集；
· 在项目根目录下新建数据集文件夹class_j，用于存放分类json文件；
· 在项目根目录下新建数据集文件夹models，用于存放训练好的模型文件；
· 神经网络model.py；
· 训练脚本train.py；
· 预测脚本predict.py
1234567891......  -->
        <p class="article-more-link">
          <a href="/2024/01/01/卷积神经网络图像分类算法小集/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AlexNet/">AlexNet</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/GoogLeNet/">GoogLeNet</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LeNet/">LeNet</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ResNet/">ResNet</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VGG/">VGG</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/卷积神经网络/">卷积神经网络</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-CentOS-LibreOffice工具包安装"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/12/28/CentOS-LibreOffice工具包安装/">CentOS-LibreOffice工具包安装</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/12/28/CentOS-LibreOffice工具包安装/" class="article-date">
	  <time datetime="2023-12-28T06:43:49.000Z" itemprop="datePublished">2023-12-28</time>
	</a>

      
    <a class="article-category-link" href="/categories/Linux/">Linux</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>·</strong> <font color="gold">系统：</font> CentOS7</p>
<p><strong>·</strong> <font color="gold">LibreOffice：</font> 7.4.5.1 稳定版</p>
<h2 id="资源下载"><a href="#资源下载" class="headerlink" title="资源下载"></a>资源下载</h2><p><strong>·</strong> 官方网站： <a href="https://zh-cn.libreoffice.org/download/libreoffice/" target="_blank" rel="noopener">https://zh-cn.libreoffice.org/download/libreoffice/</a></p>
<p><strong>·</strong> 下载地址：<a href="https://downloadarchive.documentfoundation.org/libreoffice/old/7.4.5.1/rpm/x86_64/" target="_blank" rel="noopener">https://downloadarchive.documentfoundation.org/libreoffice/old/7.4.5.1/rpm/x86_64/</a></p>
<p>选择<code>LibreOffice_7.4.5.1_Linux_x86-64_rpm.tar.gz</code>安装包和<code>LibreOffice_7.4.5.1_Linux_x86-64_rpm_langpack_zh-CN.tar.gz</code>中文语言包并下载</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>进入安装包下载目录进行解压，这里为<code>/usr/local/</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/   进入目录</span><br><span class="line">tar -zxvf LibreOffice_7.4.6.1_Linux_x86-64_rpm.tar.gz   解压libreoffice</span><br><span class="line">tar -zxvf LibreOffice7.4.6.1_Linux_x86-64_rpm_langpack_zh-CN.tar.gz   解压中文语言包</span><br></pre></td></tr></table></figure>
<p>安装<code>libreoffice</code>和语言包的rpm包，默认安装目录为<code>/opt/libreoffice7.4</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/LibreOffice_7.4.6.1_Linux_x86-64_rpm/RPMS/</span><br><span class="line">yum -y install *.rpm</span><br><span class="line">cd /usr/local/LibreOffice_7.4.6.1_Linux_x86-64_rpm_langpack_zh-CN/RPMS</span><br><span class="line">yum -y install *.rpm</span><br></pre></td></tr></table></figure>
<p>安装<code>soffice</code>，进入<code>/opt/libreoffice7.4/program</code>目录执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/libreoffice7.4/program/</span><br><span class="line">yum install cairo </span><br><span class="line">yum install cups-libs</span><br><span class="line">yum install libSM</span><br></pre></td></tr></table></figure>
<p>检查</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/libreoffice7.4/program/soffice -help</span><br></pre></td></tr></table></figure>
<p>正常输出，安装成功，接下来将<code>soffice</code>添加到环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> libreoffice</span><br><span class="line">export LibreOffice_PATH=/opt/libreoffice7.4/program</span><br><span class="line">export PATH=$LibreOffice_PATH:$PATH</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
        <!--  · 系统： CentOS7
· LibreOffice： 7.4.5.1 稳定版
资源下载· 官方网站： https://zh-cn.libreoffice.org/download/libreoffice/
· 下载地址：https://downloadarchive.documentfoundation.org/libreoffice/old/7.4.5.1/rpm/x86_64/
选......  -->
        <p class="article-more-link">
          <a href="/2023/12/28/CentOS-LibreOffice工具包安装/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LibreOffice/">LibreOffice</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux工具/">linux工具</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-LangChain + ChatGLM2-6B的本地知识问答库"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/10/24/LangChain + ChatGLM2-6B的本地知识问答库/">LangChain + ChatGLM2-6B的本地知识问答库</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/10/24/LangChain + ChatGLM2-6B的本地知识问答库/" class="article-date">
	  <time datetime="2023-10-24T01:14:34.000Z" itemprop="datePublished">2023-10-24</time>
	</a>

      
    <a class="article-category-link" href="/categories/GPT/">GPT</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>原项目Github：<a href="https://github.com/imClumsyPanda/langchain-ChatGLM" target="_blank" rel="noopener">https://github.com/imClumsyPanda/langchain-ChatGLM</a></p>
<h2 id="项目部署"><a href="#项目部署" class="headerlink" title="项目部署"></a>项目部署</h2><p><strong>·</strong> <font color="gold">v 0.2.6</font></p>
<h3 id="机器配置："><a href="#机器配置：" class="headerlink" title="机器配置："></a>机器配置：</h3><p><strong>·</strong> <font color="gold">python 环境：anaconda3 + python3.10.12</font></p>
<p><strong>·</strong> <font color="gold">GPU：RTX3090*2 + CUDA11.7</font></p>
<p><strong>·</strong> <font color="gold">torch：2.0.1（CUDA未升至12）</font></p>
<p><strong>·</strong> <font color="gold">conda：py310_dtglm</font></p>
<h3 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h3><p><strong>·</strong> <font color="gold">m3e</font> <a href="https://huggingface.co/moka-ai/m3e-base/tree/main" target="_blank" rel="noopener">https://huggingface.co/moka-ai/m3e-base/tree/main</a></p>
<p><strong>·</strong> <font color="gold">chatglm2-6b</font> <a href="https://huggingface.co/THUDM/chatglm2-6b/tree/main" target="_blank" rel="noopener">https://huggingface.co/THUDM/chatglm2-6b/tree/main</a></p>
<p>chatglm清华源 <a href="https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/?p=%2F&amp;mode=list" target="_blank" rel="noopener">https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/?p=%2F&amp;mode=list</a></p>
<p>(这里将模型全部下载至<code>/root/huggingface</code>下)</p>
<h3 id="创建虚拟环境，安装依赖"><a href="#创建虚拟环境，安装依赖" class="headerlink" title="创建虚拟环境，安装依赖"></a>创建虚拟环境，安装依赖</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">conda create -n py310_dtglm python=3.10.12</span><br><span class="line">conda activate py310_dtglm</span><br><span class="line"></span><br><span class="line">pip install --use-pep517 -r requirements.txt -i https://mirror.baidu.com/pypi/simple</span><br><span class="line">pip install --use-pep517 -r requirements_api.txt -i https://mirror.baidu.com/pypi/simple</span><br><span class="line">pip install --use-pep517 -r requirements_webui.txt -i https://mirror.baidu.com/pypi/simple</span><br></pre></td></tr></table></figure>
<h3 id="修改配置、模型路径"><a href="#修改配置、模型路径" class="headerlink" title="修改配置、模型路径"></a>修改配置、模型路径</h3><p>复制配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python copy_config_example.py</span><br></pre></td></tr></table></figure>
<p>修改配置文件</p>
<p><strong>·</strong> <font color="gold">model_config.py</font></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MODEL_ROOT_PATH = <span class="string">"/root/huggingface"</span></span><br><span class="line"></span><br><span class="line">MODEL_PATH = &#123;</span><br><span class="line">    <span class="string">"embed_model"</span>: &#123;</span><br><span class="line">		...</span><br><span class="line">        <span class="string">"m3e-base"</span>: <span class="string">"/root/huggingface/m3e-base"</span>, <span class="comment"># 修改m3e模型路径</span></span><br><span class="line">		...</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> add all supported llm models</span></span><br><span class="line">    <span class="string">"llm_model"</span>: &#123;</span><br><span class="line">		...</span><br><span class="line">        <span class="string">"chatglm2-6b"</span>: <span class="string">"/root/huggingface/chatglm2-6b"</span>, <span class="comment"># 修改chatglm2-6b模型路径</span></span><br><span class="line">		...</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">EMBEDDING_MODEL = <span class="string">"m3e-base"</span> <span class="comment"># 可以尝试最新的嵌入式sota模型：bge-large-zh-v1.5</span></span><br><span class="line">LLM_MODEL = <span class="string">"chatglm2-6b"</span></span><br></pre></td></tr></table></figure>
        <!--  原项目Github：https://github.com/imClumsyPanda/langchain-ChatGLM
项目部署· v 0.2.6
机器配置：· python 环境：anaconda3 + python3.10.12
· GPU：RTX3090*2 + CUDA11.7
· torch：2.0.1（CUDA未升至12）
· conda：py310_dtglm
模型下载· ......  -->
        <p class="article-more-link">
          <a href="/2023/10/24/LangChain + ChatGLM2-6B的本地知识问答库/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/baichuan/">baichuan</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/chat-glm/">chat-glm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/langchain-chatchat/">langchain-chatchat</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-Nebula3集群版版本多开"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/09/28/Nebula3集群版版本多开/">Nebula3集群版新旧版本多开</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/09/28/Nebula3集群版版本多开/" class="article-date">
	  <time datetime="2023-09-28T02:10:10.000Z" itemprop="datePublished">2023-09-28</time>
	</a>

      
    <a class="article-category-link" href="/categories/BigData/">BigData</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script src="\assets\js\APlayer.min.js"> </script><font color="gold"><strong>·</strong> 系统：CentOS7</font>

<font color="gold"><strong>·</strong> 已有nebula版本：2.6.1（开源社区版）</font>

<font color="gold"><strong>·</strong> 已有nebula-console版本：2.6.0</font>

<font color="gold"><strong>·</strong> 已有nebula-graph-studio版本：3.2.3</font>

<font color="gold"><strong>·</strong> 多开nebula版本：3.6.0（开源社区版）</font>

<font color="gold"><strong>·</strong> 多开nebula-graph-studio版本：3.2.3</font>

<font color="gold"><strong>·</strong> 多开nebula-console版本：3.6.0</font>

<h2 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h2><p><strong>·</strong> 参考单机部署方式，对配置文件<code>--meta_server_addrs</code>做扩展，添加meta机器</p>
<p><strong>·</strong> 区分2.6.1版本已被占用的端口，找到配置文件默认的<code>9559</code>、<code>19559</code>、<code>9669</code>、<code>19669</code>、<code>9779</code>、<code>19779</code>端口，修改为<code>8559</code>、<code>18559</code>、<code>8669</code>、<code>18669</code>、<code>8779</code>、<code>18779</code></p>
<p><strong>·</strong> 启动集群</p>
<p><strong>·</strong> 配置nebula-graph-studio默认端口为<code>7002</code></p>
<p><font color="gold"><strong>·</strong> 注</font>：双开nebula后使用同版本nebula-graph-studio即使更换了端口，也不能同时运行，可以安装nebula-console来同时启动nebula控制台</p>
<p><code>chmod 111 nebula-console</code></p>
<p><code>./nebula-console --addr &lt;host&gt; --port 9669 -u root -p nebula</code></p>
<p><code>./nebula-console --addr &lt;host&gt; --port 8669 -u root -p nebula</code></p>

      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/database/">database</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nebula/">nebula</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-Nebula3单机版快速安装"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/09/27/Nebula3单机版快速安装/">Nebula3单机版快速安装</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/09/27/Nebula3单机版快速安装/" class="article-date">
	  <time datetime="2023-09-27T08:12:31.000Z" itemprop="datePublished">2023-09-27</time>
	</a>

      
    <a class="article-category-link" href="/categories/BigData/">BigData</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <font color="gold"><strong>·</strong> 系统：CentOS7</font>

<font color="gold"><strong>·</strong> nebula版本：3.6.0（开源社区版）</font>

<font color="gold"><strong>·</strong> nebula-graph-studio版本：3.2.3</font>

<h2 id="单机部署"><a href="#单机部署" class="headerlink" title="单机部署"></a>单机部署</h2><h3 id="tar包源码下载"><a href="#tar包源码下载" class="headerlink" title="tar包源码下载"></a>tar包源码下载</h3><p><code>wget https://oss-cdn.nebula-graph.com.cn/package/3.6.0/nebula-graph-3.6.0.el7.x86_64.tar.gz</code></p>
<h3 id="解压并重命名"><a href="#解压并重命名" class="headerlink" title="解压并重命名"></a>解压并重命名</h3><p><code>tar -xvzf nebula-graph-3.6.0.el7.x86_64.tar.gz</code></p>
<p><code>mv nebula-graph-3.6.0.el7.x86_64 nebula</code></p>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p><code>cd nebula/etc</code></p>
<p><code>mv nebula-graphd.conf.default nebula-graphd.conf</code></p>
<p><code>mv nebula-metad.conf.default nebula-metad.conf</code></p>
<p><code>mv nebula-storaged.conf.default nebula-storaged.conf</code></p>
<p>修改对应文件存储位置、节点ip地址，集群同理</p>
        <!--  · 系统：CentOS7

· nebula版本：3.6.0（开源社区版）

· nebula-graph-studio版本：3.2.3

单机部署tar包源码下载wget https://oss-cdn.nebula-graph.com.cn/package/3.6.0/nebula-graph-3.6.0.el7.x86_64.tar.gz
解压并重命名tar -xvzf nebula......  -->
        <p class="article-more-link">
          <a href="/2023/09/27/Nebula3单机版快速安装/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/database/">database</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/nebula/">nebula</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-基于VGG16神经网络实现图像艺术风格转换"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/">基于VGG16神经网络实现图像艺术风格转换</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/" class="article-date">
	  <time datetime="2023-09-07T07:04:43.000Z" itemprop="datePublished">2023-09-07</time>
	</a>

      
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <script src="\assets\js\APlayer.min.js"> </script><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>通过vgg16或其他神经网络提取图像特征，并使用格拉姆矩阵（Gram matrix）进行图像风格的迁移。</p>
<h3 id="VGG16"><a href="#VGG16" class="headerlink" title="VGG16"></a>VGG16</h3><p>不必多说，2014年ImageNet图像分类竞赛亚军，定位竞赛冠军；VGG网络采用连续的小卷积核（3x3）和池化层构建深度神经网络，网络深度可以达到16层或19层，其中VGG16和VGG19最为著名。VGG16和VGG19网络架构非常相似，都由多个卷积层和池化层交替堆叠而成，最后使用全连接层进行分类。两者的区别在于网络的深度和参数量，VGG19相对于VGG16增加了3个卷积层和一个全连接层，参数量也更多。</p>
<p>可在keras直接使用vgg16/19源码，自动下载相关预训练模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.vgg16 <span class="keyword">import</span> VGG16</span><br><span class="line"><span class="keyword">from</span> keras.applications.vgg19 <span class="keyword">import</span> VGG19</span><br></pre></td></tr></table></figure>
<p>这里结合transform，在torch中构建神经网络</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># VGG16神经网络定义</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG16</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""Vgg16 Net"""</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, requires_grad=False)</span>:</span></span><br><span class="line">        super(VGG16, self).__init__()</span><br><span class="line">        vgg_pretrained_features = models.vgg16(pretrained=<span class="literal">True</span>).features</span><br><span class="line">        self.slice1 = torch.nn.Sequential()</span><br><span class="line">        self.slice2 = torch.nn.Sequential()</span><br><span class="line">        self.slice3 = torch.nn.Sequential()</span><br><span class="line">        self.slice4 = torch.nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">            self.slice1.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">4</span>, <span class="number">9</span>):</span><br><span class="line">            self.slice2.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">9</span>, <span class="number">16</span>):</span><br><span class="line">            self.slice3.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">16</span>, <span class="number">23</span>):</span><br><span class="line">            self.slice4.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> requires_grad:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> self.parameters():</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        h = self.slice1(X)</span><br><span class="line">        h_relu1_2 = h</span><br><span class="line">        h = self.slice2(h)</span><br><span class="line">        h_relu2_2 = h</span><br><span class="line">        h = self.slice3(h)</span><br><span class="line">        h_relu3_3 = h</span><br><span class="line">        h = self.slice4(h)</span><br><span class="line">        h_relu4_3 = h</span><br><span class="line"></span><br><span class="line">        vgg_outputs = namedtuple(<span class="string">"VggOutputs"</span>, [<span class="string">"relu1_2"</span>, <span class="string">"relu2_2"</span>, <span class="string">"relu3_3"</span>, <span class="string">"relu4_3"</span>])</span><br><span class="line">        output = vgg_outputs(h_relu1_2, h_relu2_2, h_relu3_3, h_relu4_3)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TransformerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(TransformerNet, self).__init__()</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            ConvBlock(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">9</span>, stride=<span class="number">1</span>),</span><br><span class="line">            ConvBlock(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            ConvBlock(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ResidualBlock(<span class="number">128</span>),</span><br><span class="line">            ConvBlock(<span class="number">128</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, upsample=<span class="literal">True</span>),</span><br><span class="line">            ConvBlock(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, upsample=<span class="literal">True</span>),</span><br><span class="line">            ConvBlock(<span class="number">32</span>, <span class="number">3</span>, kernel_size=<span class="number">9</span>, stride=<span class="number">1</span>, normalize=<span class="literal">False</span>, relu=<span class="literal">False</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.model(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResidualBlock</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, channels)</span>:</span></span><br><span class="line">        super(ResidualBlock, self).__init__()</span><br><span class="line">        self.block = nn.Sequential(</span><br><span class="line">            ConvBlock(channels, channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, normalize=<span class="literal">True</span>, relu=<span class="literal">True</span>),</span><br><span class="line">            ConvBlock(channels, channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, normalize=<span class="literal">True</span>, relu=<span class="literal">False</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.block(x) + x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvBlock</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, upsample=False, normalize=True, relu=True)</span>:</span></span><br><span class="line">        super(ConvBlock, self).__init__()</span><br><span class="line">        self.upsample = upsample</span><br><span class="line">        self.block = nn.Sequential(</span><br><span class="line">            nn.ReflectionPad2d(kernel_size // <span class="number">2</span>),</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size, (stride,))</span><br><span class="line">        )</span><br><span class="line">        self.norm = nn.InstanceNorm2d(out_channels, affine=<span class="literal">True</span>) <span class="keyword">if</span> normalize <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        self.relu = relu</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.upsample:</span><br><span class="line">            x = F.interpolate(x, scale_factor=<span class="number">2</span>)</span><br><span class="line">        x = self.block(x)</span><br><span class="line">        <span class="keyword">if</span> self.norm <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            x = self.norm(x)</span><br><span class="line">        <span class="keyword">if</span> self.relu:</span><br><span class="line">            x = F.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">测试模型</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    input1 = torch.rand([<span class="number">224</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>])</span><br><span class="line">    model_x = VGG16()</span><br><span class="line">    print(model_x)</span><br></pre></td></tr></table></figure>
<h3 id="格拉姆矩阵"><a href="#格拉姆矩阵" class="headerlink" title="格拉姆矩阵"></a>格拉姆矩阵</h3><p>格拉姆矩阵（Gram matrix）即n维欧式空间中任意k个向量之间两两的内积所组成的矩阵，是一个对称矩阵。</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/A.png" alt></p>
<p>更直观的理解：</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/B.png" alt></p>
<p>输入图像的feature map为[ ch, h, w]。我们经过flatten（即是将h<em>w进行平铺成一维向量）和矩阵转置操作，可以变形为[ ch, h</em>w]和[ h*w, ch]的矩阵。再对两个作内积得到格拉姆矩阵。</p>
<p>使用格拉姆矩阵进行风格迁移：</p>
<p>1.准备目标图像和目标风格图像；</p>
<p>2.使用深层网络加白噪声提取目标图像和风格目标的特征向量。对两个图像的特征向量计算格拉姆矩阵，以矩阵差异最小化为优化目标，不断调整目标图像，使风格不断相似。</p>
<p>torch中格拉姆矩阵代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram_matrix</span><span class="params">(y)</span>:</span></span><br><span class="line">    (b, c, h, w) = y.size()</span><br><span class="line">    features = y.view(b, c, w * h)</span><br><span class="line">    features_t = features.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    gram = features.bmm(features_t) / (c * h * w)</span><br><span class="line">    <span class="keyword">return</span> gram</span><br></pre></td></tr></table></figure>
<h2 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h2><p>准备训练文件和风格图片，例如随机图像*20和梵高名作星月夜</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/C.png" alt></p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/D.png" alt></p>
<h3 id="utils-py工具"><a href="#utils-py工具" class="headerlink" title="utils.py工具"></a>utils.py工具</h3><p>配置训练参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">parser = argparse.ArgumentParser(description=<span class="string">"Parser 4 Training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--style"</span>, type=str, default=<span class="string">"images/styles/the_starry_night.jpg"</span>, help=<span class="string">"Path 2 style image"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--dataset"</span>, type=str, help=<span class="string">"path 2 training dataset"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--epochs"</span>, type=int, default=<span class="number">1</span>, help=<span class="string">"Number of training epochs"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--batch_size"</span>, type=int, default=<span class="number">4</span>, help=<span class="string">"Batch size 4 training"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--image_size"</span>, type=int, default=<span class="number">256</span>, help=<span class="string">"Size of training images"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--style_size"</span>, type=int, help=<span class="string">"Size of style image"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lr"</span>, type=float, default=<span class="number">1e-3</span>, help=<span class="string">"Learning rate"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lambda_img"</span>, type=float, default=<span class="number">1e5</span>, help=<span class="string">"Weight 4 image loss"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--lambda_style"</span>, type=float, default=<span class="number">1e10</span>, help=<span class="string">"Weight 4 style loss"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--model_path"</span>, type=str, help=<span class="string">"Optional path 2 checkpoint model"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--model_checkpoint"</span>, type=int, default=<span class="number">1000</span>, help=<span class="string">"Batches 4 saving model"</span>)</span><br><span class="line">parser.add_argument(<span class="string">"--result_checkpoint"</span>, type=int, default=<span class="number">1000</span>, help=<span class="string">"Batches 4 saving image result"</span>)</span><br></pre></td></tr></table></figure>
<p>使用神经网络进行风格训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_transform</span><span class="params">(image_size)</span>:</span></span><br><span class="line">    transform = transforms.Compose(</span><br><span class="line">        [</span><br><span class="line">            transforms.Resize(int(image_size * <span class="number">1.15</span>)),</span><br><span class="line">            transforms.RandomCrop(image_size),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            transforms.Normalize(mean, std),</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> transform</span><br></pre></td></tr></table></figure>
<p>使用神经网络进行风格转换</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_transform</span><span class="params">(image_size=None)</span>:</span></span><br><span class="line">    resize = [transforms.Resize(image_size)] <span class="keyword">if</span> image_size <span class="keyword">else</span> []</span><br><span class="line">    transform = transforms.Compose(resize + [transforms.ToTensor(), transforms.Normalize(mean, std)])</span><br><span class="line">    <span class="keyword">return</span> transform</span><br></pre></td></tr></table></figure>
<p>使用均值和标准对图像张量进行反规范化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">denormalize</span><span class="params">(tensors)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        tensors[:, c].mul_(std[c]).add_(mean[c])</span><br><span class="line">    <span class="keyword">return</span> tensors</span><br></pre></td></tr></table></figure>
<h3 id="train-py训练脚本"><a href="#train-py训练脚本" class="headerlink" title="train.py训练脚本"></a>train.py训练脚本</h3><p>训练配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_args = TrainArgs()</span><br><span class="line">args = train_args.initialize().parse_args()</span><br><span class="line"></span><br><span class="line">args.dataset = <span class="string">'./dataset'</span></span><br><span class="line">args.style = <span class="string">'./images/styles/the_starry_night.jpg'</span></span><br><span class="line">args.epochs = <span class="number">2400</span> <span class="comment"># epochs*(数据集/batch_size)是1000的公倍数</span></span><br><span class="line">args.batch_size = <span class="number">4</span></span><br><span class="line">args.image_size = <span class="number">256</span></span><br></pre></td></tr></table></figure>
<p>训练流程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">style_name = args.style.split(<span class="string">"/"</span>)[<span class="number">-1</span>].split(<span class="string">"."</span>)[<span class="number">0</span>]</span><br><span class="line">os.makedirs(<span class="string">f"images/train/<span class="subst">&#123;style_name&#125;</span>_training"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">os.makedirs(<span class="string">f"checkpoints"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line">train_dataset = datasets.ImageFolder(args.dataset, train_transform(args.image_size))</span><br><span class="line">dataloader = DataLoader(train_dataset, batch_size=args.batch_size)</span><br><span class="line">transformer = TransformerNet().to(device)</span><br><span class="line">vgg = VGG16(requires_grad=<span class="literal">False</span>).to(device)</span><br><span class="line"><span class="keyword">if</span> args.model_path:</span><br><span class="line">    transformer.load_state_dict(torch.load(args.model_path))</span><br><span class="line">optimizer = Adam(transformer.parameters(), args.lr)</span><br><span class="line">l2_loss = torch.nn.MSELoss().to(device)</span><br><span class="line">style = style_transform(args.style_size)(Image.open(args.style))</span><br><span class="line">style = style.repeat(args.batch_size, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).to(device)</span><br><span class="line">features_style = vgg(style)</span><br><span class="line">gram_style = [gram_matrix(y) <span class="keyword">for</span> y <span class="keyword">in</span> features_style]</span><br><span class="line">image_samples = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> random.sample(glob.glob(<span class="string">f"<span class="subst">&#123;args.dataset&#125;</span>/*/*"</span>), len(train_dataset)):</span><br><span class="line">    image_samples += [style_transform(args.image_size)(Image.open(path).resize((<span class="number">224</span>, <span class="number">224</span>)))]</span><br><span class="line">image_samples = torch.stack(image_samples)</span><br></pre></td></tr></table></figure>
<p>启动训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_result</span><span class="params">(sample)</span>:</span></span><br><span class="line">    transformer.eval()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        output = transformer(image_samples.to(device))</span><br><span class="line">    image_rgb = denormalize(torch.cat((image_samples.cpu(), output.cpu()), <span class="number">2</span>))</span><br><span class="line">    save_image(image_rgb, <span class="string">f"images/train/<span class="subst">&#123;style_name&#125;</span>_training/<span class="subst">&#123;sample&#125;</span>.jpg"</span>, nrow=<span class="number">4</span>)</span><br><span class="line">    transformer.train()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_model</span><span class="params">(sample)</span>:</span></span><br><span class="line">    torch.save(transformer.state_dict(), <span class="string">f"checkpoints/<span class="subst">&#123;style_name&#125;</span>_<span class="subst">&#123;sample&#125;</span>.pth"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(args.epochs):</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> range(len(dataloader)):</span><br><span class="line">        batch_i = line</span><br><span class="line">        batches_done = epoch * len(dataloader) + batch_i + <span class="number">1</span></span><br><span class="line">        images = list(dataloader)[line][<span class="number">0</span>]</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        images_original = images.to(device)</span><br><span class="line">        images_transformed = transformer(images_original)</span><br><span class="line"></span><br><span class="line">        features_original = vgg(images_original)</span><br><span class="line">        features_transformed = vgg(images_transformed)</span><br><span class="line"></span><br><span class="line">        img_loss = args.lambda_img * l2_loss(features_transformed.relu2_2, features_original.relu2_2)</span><br><span class="line"></span><br><span class="line">        style_loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> ft_y, gm_s <span class="keyword">in</span> zip(features_transformed, gram_style):</span><br><span class="line">            gm_y = gram_matrix(ft_y)</span><br><span class="line">            style_loss += l2_loss(gm_y, gm_s[: images.size(<span class="number">0</span>), :, :])</span><br><span class="line">        style_loss *= args.lambda_style</span><br><span class="line"></span><br><span class="line">        total_loss = img_loss + style_loss</span><br><span class="line">        total_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batches_done % args.result_checkpoint == <span class="number">0</span>:</span><br><span class="line">            save_result(batches_done)</span><br><span class="line">        <span class="keyword">if</span> args.model_checkpoint &gt; <span class="number">0</span> <span class="keyword">and</span> batches_done % args.model_checkpoint == <span class="number">0</span>:</span><br><span class="line">            save_model(batches_done)</span><br></pre></td></tr></table></figure>
<p>第1000次迭代</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/1000.jpg" alt></p>
<p>第12000次迭代（2400epoch * (20/batch_size)），效果明显</p>
<p><img src="/2023/09/07/基于VGG16神经网络实现图像艺术风格转换/12000.jpg" alt></p>
<p>到这一步，训练结束，可以预测结果</p>
<h2 id="预测："><a href="#预测：" class="headerlink" title="预测："></a>预测：</h2><p>配置预测参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">predict_args = PredictArgs()</span><br><span class="line">args = predict_args.initialize().parse_args()</span><br><span class="line">args.image_path = <span class="string">'./images/input/001.jpg'</span></span><br><span class="line">args.model_path = <span class="string">'./checkpoints/the_starry_night_12000.pth'</span></span><br></pre></td></tr></table></figure>
<p>预测代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">os.makedirs(<span class="string">"images/output"</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">   device = torch.device(<span class="string">'cpu'</span>)<span class="comment">#("cuda" if torch.cuda.is_available() else "cpu")</span></span><br><span class="line">   transform = style_transform()</span><br><span class="line">   transformer = TransformerNet().to(device)</span><br><span class="line">   transformer.load_state_dict(torch.load(mod_path))</span><br><span class="line">   transformer.eval()</span><br><span class="line">   image_tensor = Variable(transform(Image.open(img_path))).to(device)</span><br><span class="line">   image_tensor = image_tensor.unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">   <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">       output_image = denormalize(transformer(image_tensor)).cpu()</span><br><span class="line">       </span><br><span class="line">   name = img_path.split(<span class="string">"/"</span>)[<span class="number">-1</span>]</span><br><span class="line">   save_image(output_image, <span class="string">f"images/output/output_<span class="subst">&#123;name&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="思路·参考"><a href="#思路·参考" class="headerlink" title="思路·参考"></a>思路·参考</h2><p><a href="https://github.com/elleryqueenhomels/fast_neural_style_transfer/tree/master" target="_blank" rel="noopener">https://github.com/elleryqueenhomels/fast_neural_style_transfer/tree/master</a></p>
<p><a href="https://github.com/AaronJny/DeepLearningExamples/tree/master/tf2-neural-style-transfer" target="_blank" rel="noopener">https://github.com/AaronJny/DeepLearningExamples/tree/master/tf2-neural-style-transfer</a></p>
<p><a href="https://github.com/Huage001/PaintTransformer" target="_blank" rel="noopener">https://github.com/Huage001/PaintTransformer</a></p>
<p><a href="https://github.com/eriklindernoren/Fast-Neural-Style-Transfer/tree/master" target="_blank" rel="noopener">https://github.com/eriklindernoren/Fast-Neural-Style-Transfer/tree/master</a></p>
<p><a href="https://github.com/NeverGiveU/PaintTransformer-Pytorch-master" target="_blank" rel="noopener">https://github.com/NeverGiveU/PaintTransformer-Pytorch-master</a></p>
<p><a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" target="_blank" rel="noopener">https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix</a></p>

      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/VGG/">VGG</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/卷积神经网络/">卷积神经网络</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-paddleDetection Demo"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/08/31/paddleDetection Demo/">paddleDetection Demo</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/08/31/paddleDetection Demo/" class="article-date">
	  <time datetime="2023-08-31T04:20:20.000Z" itemprop="datePublished">2023-08-31</time>
	</a>

      
    <a class="article-category-link" href="/categories/深度学习/">深度学习</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="PPHuman"><a href="#PPHuman" class="headerlink" title="PPHuman"></a>PPHuman</h2><h3 id="行人属性识别"><a href="#行人属性识别" class="headerlink" title="行人属性识别"></a>行人属性识别</h3><h4 id="行人属性"><a href="#行人属性" class="headerlink" title="行人属性"></a>行人属性</h4><p>cfg：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">crop_thresh:</span> <span class="number">0.5</span></span><br><span class="line"><span class="attr">attr_thresh:</span> <span class="number">0.5</span></span><br><span class="line"><span class="attr">kpt_thresh:</span> <span class="number">0.2</span></span><br><span class="line"><span class="attr">visual:</span> <span class="literal">True</span></span><br><span class="line"><span class="attr">warmup_frame:</span> <span class="number">50</span></span><br><span class="line"></span><br><span class="line"><span class="attr">DET:</span></span><br><span class="line">  <span class="attr">model_dir:</span> <span class="string">https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip</span></span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">MOT:</span></span><br><span class="line">  <span class="attr">model_dir:</span> <span class="string">https://bj.bcebos.com/v1/paddledet/models/pipeline/mot_ppyoloe_l_36e_pipeline.zip</span></span><br><span class="line">  <span class="attr">tracker_config:</span> <span class="string">/exp/work/video/PaddleDetection/deploy/pipeline/config/tracker_config.yml</span></span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">1</span></span><br><span class="line">  <span class="attr">skip_frame_num:</span> <span class="number">-1</span> <span class="comment"># preferably no more than 3</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="attr">KPT:</span></span><br><span class="line">  <span class="attr">model_dir:</span> <span class="string">https://bj.bcebos.com/v1/paddledet/models/pipeline/dark_hrnet_w32_256x192.zip</span></span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">8</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ATTR:</span></span><br><span class="line">  <span class="attr">model_dir:</span>  <span class="string">https://bj.bcebos.com/v1/paddledet/models/pipeline/PPLCNet_x1_0_person_attribute_945_infer.zip</span></span><br><span class="line">  <span class="attr">batch_size:</span> <span class="number">8</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p>cli：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python deploy/pipeline/pipeline.py --config deploy/pipeline/config/cache/cfg_human.yml --device=gpu --video_file=demo_input/human.mp4 --output_dir=demo_output/</span><br></pre></td></tr></table></figure>
<p><img src="/2023/08/31/paddleDetection Demo/行人属性.gif" alt></p>
        <!--  PPHuman行人属性识别行人属性cfg：
12345678910111213141516171819202122232425crop_thresh: 0.5attr_thresh: 0.5kpt_thresh: 0.2visual: Truewarmup_frame: 50DET:  model_dir: https://bj.bcebos.com/v1/paddledet/models......  -->
        <p class="article-more-link">
          <a href="/2023/08/31/paddleDetection Demo/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/opencv/">opencv</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paddlepaddle/">paddlepaddle</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-LiveGBS国标GB-T28181视频流媒体平台"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/08/18/LiveGBS国标GB-T28181视频流媒体平台/">LiveGBS国标GB/T28181视频流媒体平台</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/08/18/LiveGBS国标GB-T28181视频流媒体平台/" class="article-date">
	  <time datetime="2023-08-18T08:34:45.000Z" itemprop="datePublished">2023-08-18</time>
	</a>

      
    <a class="article-category-link" href="/categories/计算机视觉/">计算机视觉</a>

      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="软件包下载"><a href="#软件包下载" class="headerlink" title="软件包下载"></a>软件包下载</h2><p>LiveGBS GB28181流媒体服务下载地址：<a href="https://www.liveqing.com/docs/download/LiveGBS.html#%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD" target="_blank" rel="noopener">https://www.liveqing.com/docs/download/LiveGBS.html#%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD</a></p>
<p>选择windows版本的<code>LiveGBS 信令服务</code>和<code>LiveGBS</code>流媒体服务，免费版授权周期为26天，届时需要手动更新软件服务</p>
<p><img src="/2023/08/18/LiveGBS国标GB-T28181视频流媒体平台/A.png" style="zoom:80%;"></p>
<h2 id="安装LiveGBS-GB28281"><a href="#安装LiveGBS-GB28281" class="headerlink" title="安装LiveGBS GB28281"></a>安装LiveGBS GB28281</h2><p>解压下载好的软件包，分别启动<code>LiveCMS.exe</code>和<code>LiveSMS.exe</code>，如果有默认端口被占用的情况可以修改对应的<code>livecms.ini</code>或<code>livesms.ini</code>配置文件，这里我将LiveGBS的默认端口从10000修改为10005</p>
<p>成功启动后后台出现livecms和livesms的图标</p>
<p><img src="/2023/08/18/LiveGBS国标GB-T28181视频流媒体平台/B.png" alt></p>
        <!--  软件包下载LiveGBS GB28181流媒体服务下载地址：https://www.liveqing.com/docs/download/LiveGBS.html#%E7%89%88%E6%9C%AC%E4%B8%8B%E8%BD%BD
选择windows版本的LiveGBS 信令服务和LiveGBS流媒体服务，免费版授权周期为26天，届时需要手动更新软件服务

安装LiveGBS GB2......  -->
        <p class="article-more-link">
          <a href="/2023/08/18/LiveGBS国标GB-T28181视频流媒体平台/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/LiveGBS/">LiveGBS</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  
    <article id="post-paddleDetection-视频OCR"  class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" itemprop="name">
      <a class="article-title" href="/2023/08/14/paddleDetection-视频OCR/">paddleDetection-视频OCR</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2023/08/14/paddleDetection-视频OCR/" class="article-date">
	  <time datetime="2023-08-14T03:15:55.000Z" itemprop="datePublished">2023-08-14</time>
	</a>

      
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="PPOCR-V4"><a href="#PPOCR-V4" class="headerlink" title="PPOCR_V4"></a>PPOCR_V4</h2><p>安装百度最新ppocr_v4库，使用虚拟环境为py39_vio，本虚拟环境不可与人脸识别（py38_arcface）兼容（opencv版本不兼容）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install paddleocr --user -i https://mirror.baidu.com/pypi/simple</span><br></pre></td></tr></table></figure>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><code>cfg_utils.py</code>新增cfg<code>--ocr</code>，设置True为开启，默认False</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">parser.add_argument(</span><br><span class="line">    <span class="string">"--ocr"</span>,</span><br><span class="line">    type=bool,</span><br><span class="line">    default=<span class="literal">False</span>,</span><br><span class="line">    help=<span class="string">"use paddlepaddle-ocr"</span>)</span><br></pre></td></tr></table></figure>
<p><code>pipeline.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> python.visualize <span class="keyword">import</span> visualize_box_mask, visualize_attr, visualize_pose, visualize_action, visualize_vehicleplate, visualize_vehiclepress, visualize_lane, visualize_vehicle_retrograde, visualize_ocr</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PipePredictor</span><span class="params">(object)</span>:</span>  </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, args, cfg, is_video=True, multi_camera=False)</span>:</span></span><br><span class="line">    	self.ocr = args.ocr</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_video</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                    image_rgb,</span></span></span><br><span class="line"><span class="function"><span class="params">                    result,</span></span></span><br><span class="line"><span class="function"><span class="params">                    collector,</span></span></span><br><span class="line"><span class="function"><span class="params">                    frame_id,</span></span></span><br><span class="line"><span class="function"><span class="params">                    fps,</span></span></span><br><span class="line"><span class="function"><span class="params">                    entrance=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    records=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    center_traj=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                    do_illegal_parking_recognition=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                    illegal_parking_dict=None)</span>:</span></span><br><span class="line">    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)</span><br><span class="line">    mot_res = copy.deepcopy(result.get(<span class="string">'mot'</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> self.ocr:</span><br><span class="line">        lock.acquire() <span class="comment"># 加锁，paddleOCR是线程不安全的</span></span><br><span class="line">        ocr_result = ocr.ocr(image, cls=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">        lock.release()</span><br><span class="line">        ocr_boxes = [line[<span class="number">0</span>] <span class="keyword">for</span> line <span class="keyword">in</span> ocr_result]</span><br><span class="line">        ocr_txts = [line[<span class="number">1</span>][<span class="number">0</span>] <span class="keyword">for</span> line <span class="keyword">in</span> ocr_result]</span><br><span class="line">        ocr_scores = [line[<span class="number">1</span>][<span class="number">1</span>] <span class="keyword">for</span> line <span class="keyword">in</span> ocr_result]</span><br><span class="line">        </span><br><span class="line">        image = visualize_ocr(image, ocr_boxes, ocr_txts, ocr_scores)</span><br></pre></td></tr></table></figure>
<p><code>visualize.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize_ocr</span><span class="params">(im, boxes, texts, score)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(im, str):</span><br><span class="line">        im = Image.open(im)</span><br><span class="line">        im = np.ascontiguousarray(np.copy(im))</span><br><span class="line">        im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        im = np.ascontiguousarray(np.copy(im))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建透明图层，为图像添加文字水印</span></span><br><span class="line">    im = Image.fromarray(im)</span><br><span class="line">    im = im.convert(<span class="string">'RGBA'</span>)</span><br><span class="line">    im_canvas = Image.new(<span class="string">'RGBA'</span>, im.size, (<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, res <span class="keyword">in</span> enumerate(texts):</span><br><span class="line">        <span class="keyword">if</span> boxes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            box = boxes[i]</span><br><span class="line">            text = res</span><br><span class="line">            <span class="keyword">if</span> text == <span class="string">""</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">            text_scale = max(<span class="number">1.0</span>, int(box[<span class="number">2</span>][<span class="number">1</span>] - box[<span class="number">1</span>][<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">            draw = ImageDraw.Draw(im_canvas)</span><br><span class="line">            draw.text(</span><br><span class="line">                (box[<span class="number">0</span>][<span class="number">0</span>], box[<span class="number">0</span>][<span class="number">1</span>]),</span><br><span class="line">                text,</span><br><span class="line">                font=ImageFont.truetype(font_file, size=int(text_scale)),</span><br><span class="line">                fill=(<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>, <span class="number">85</span>)) <span class="comment"># 第四位是透明度</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                draw.rectangle(</span><br><span class="line">                    ((box[<span class="number">0</span>][<span class="number">0</span>], box[<span class="number">0</span>][<span class="number">1</span>]), (box[<span class="number">2</span>][<span class="number">0</span>], box[<span class="number">2</span>][<span class="number">1</span>])),</span><br><span class="line">                    fill=<span class="literal">None</span>,</span><br><span class="line">                    outline=(<span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>),</span><br><span class="line">                    width=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 复合图层</span></span><br><span class="line">    im = Image.alpha_composite(im, im_canvas)</span><br><span class="line">    im = im.convert(<span class="string">'RGB'</span>)</span><br><span class="line">    <span class="comment"># 还原连续存储数组</span></span><br><span class="line">    im = np.ascontiguousarray(np.copy(im))</span><br><span class="line">    <span class="keyword">return</span> im</span><br></pre></td></tr></table></figure>
        <!--  PPOCR_V4安装百度最新ppocr_v4库，使用虚拟环境为py39_vio，本虚拟环境不可与人脸识别（py38_arcface）兼容（opencv版本不兼容）
1pip install paddleocr --user -i https://mirror.baidu.com/pypi/simple
代码cfg_utils.py新增cfg--ocr，设置True为开启，默认False
1......  -->
        <p class="article-more-link">
          <a href="/2023/08/14/paddleDetection-视频OCR/#more">Read More</a>
        </p>
      
    </div>
    <footer class="article-footer">
      
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/OCR/">OCR</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/paddlepaddle/">paddlepaddle</a></li></ul>

    </footer>
  </div>
  
</article>

<!-- Table of Contents -->

  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a>
  </nav>

</section>
        
      </div>
      
        <div align="center" style="margin-top: 30px;"><hr class="hr" style="margin:0px; height:3px;"></div>
      
      <footer id="footer">
  

  <div class="container">
      	<div class="row">
	      <p> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/iTimeTraveler/hexo-theme-hiker" target="_blank">Hexo-theme-hiker</a> </p>
	      <p id="copyRightEn">Copyright &copy; 2017 - 2025 青域 All Rights Reserved.</p>

	      
    		<p class="busuanzi_uv">
				UV : <span id="busuanzi_value_site_uv"></span> |  
				PV : <span id="busuanzi_value_site_pv"></span>
		    </p>
  		   
		</div>

		
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");
    var allheader = document.getElementById("allheader");

    wrapdiv.style.minHeight = document.body.offsetHeight + "px";
    if (allheader != null) {
      contentdiv.style.minHeight = document.body.offsetHeight - allheader.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    } else {
      contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("footer").offsetHeight + "px";
    }
</script>
    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/scripts.js"></script>


  <script src="/js/home.js"></script>










	<div style="display: none;">
    <script src="https://s95.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
  </div>



	<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






  </div>

  <div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true" style="display: none;">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title" id="myModalLabel">设置</h2>
      </div>
      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">


      <div class="modal-body">
          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseOne" onclick="javascript:setFontSize();" aria-expanded="true" aria-controls="collapseOne">
              正文字号大小
            </a>
          </div>
          <div id="collapseOne" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingOne">
          <div class="panel-body">
            您已调整页面字体大小
          </div>
        </div>
      


          <div style="margin:6px;">
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseTwo" onclick="javascript:setBackground();" aria-expanded="true" aria-controls="collapseTwo">
              夜间护眼模式
            </a>
        </div>
          <div id="collapseTwo" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingTwo">
          <div class="panel-body">
            夜间模式已经开启，再次单击按钮即可关闭 
          </div>
        </div>

        <div>
            <a data-toggle="collapse" data-parent="#accordion" href="#collapseThree" aria-expanded="true" aria-controls="collapseThree">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关 于&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</a>
        </div>
         <div id="collapseThree" class="panel-collapse collapse" role="tabpanel" aria-labelledby="headingThree">
          <div class="panel-body">
            青域
          </div>
          <div class="panel-body">
            Copyright © 2025 tianL.R All Rights Reserved.
          </div>
        </div>
      </div>


      <hr style="margin-top:0px; margin-bottom:0px; width:80%; border-top: 1px solid #000;">
      <hr style="margin-top:2px; margin-bottom:0px; width:80%; border-top: 3px solid #000;">
      <div class="modal-footer">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
      </div>
    </div>
  </div>
</div>
  
  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
  
</script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"left","width":170,"height":340},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script></body>
</html>